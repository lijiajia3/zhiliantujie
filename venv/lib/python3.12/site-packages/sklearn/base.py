




import copy
import functools
import inspect
import platform
import re
import warnings
from collections import defaultdict

import numpy as np

from . import __version__
from ._config import config_context, get_config
from .exceptions import InconsistentVersionWarning
from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr
from .utils._metadata_requests import _MetadataRequester, _routing_enabled
from .utils._param_validation import validate_parameter_constraints
from .utils._set_output import _SetOutputMixin
from .utils._tags import (
    ClassifierTags,
    RegressorTags,
    Tags,
    TargetTags,
    TransformerTags,
    get_tags,
)
from .utils.fixes import _IS_32BIT
from .utils.validation import (
    _check_feature_names,
    _check_feature_names_in,
    _check_n_features,
    _generate_get_feature_names_out,
    _is_fitted,
    check_array,
    check_is_fitted,
    validate_data,
)


def clone(estimator, *, safe=True):
    
    if hasattr(estimator, "__sklearn_clone__") and not inspect.isclass(estimator):
        return estimator.__sklearn_clone__()
    return _clone_parametrized(estimator, safe=safe)


def _clone_parametrized(estimator, *, safe=True):
    

    estimator_type = type(estimator)
    if estimator_type is dict:
        return {k: clone(v, safe=safe) for k, v in estimator.items()}
    elif estimator_type in (list, tuple, set, frozenset):
        return estimator_type([clone(e, safe=safe) for e in estimator])
    elif not hasattr(estimator, "get_params") or isinstance(estimator, type):
        if not safe:
            return copy.deepcopy(estimator)
        else:
            if isinstance(estimator, type):
                raise TypeError(
                    "Cannot clone object. "
                    + "You should provide an instance of "
                    + "scikit-learn estimator instead of a class."
                )
            else:
                raise TypeError(
                    "Cannot clone object '%s' (type %s): "
                    "it does not seem to be a scikit-learn "
                    "estimator as it does not implement a "
                    "'get_params' method." % (repr(estimator), type(estimator))
                )

    klass = estimator.__class__
    new_object_params = estimator.get_params(deep=False)
    for name, param in new_object_params.items():
        new_object_params[name] = clone(param, safe=False)

    new_object = klass(**new_object_params)
    try:
        new_object._metadata_request = copy.deepcopy(estimator._metadata_request)
    except AttributeError:
        pass

    params_set = new_object.get_params(deep=False)

    
    for name in new_object_params:
        param1 = new_object_params[name]
        param2 = params_set[name]
        if param1 is not param2:
            raise RuntimeError(
                "Cannot clone object %s, as the constructor "
                "either does not set or modifies parameter %s" % (estimator, name)
            )

    
    
    if hasattr(estimator, "_sklearn_output_config"):
        new_object._sklearn_output_config = copy.deepcopy(
            estimator._sklearn_output_config
        )
    return new_object


class BaseEstimator(_HTMLDocumentationLinkMixin, _MetadataRequester):
    

    @classmethod
    def _get_param_names(cls):
        
        
        
        init = getattr(cls.__init__, "deprecated_original", cls.__init__)
        if init is object.__init__:
            
            return []

        
        
        init_signature = inspect.signature(init)
        
        parameters = [
            p
            for p in init_signature.parameters.values()
            if p.name != "self" and p.kind != p.VAR_KEYWORD
        ]
        for p in parameters:
            if p.kind == p.VAR_POSITIONAL:
                raise RuntimeError(
                    "scikit-learn estimators should always "
                    "specify their parameters in the signature"
                    " of their __init__ (no varargs)."
                    " %s with constructor %s doesn't "
                    " follow this convention." % (cls, init_signature)
                )
        
        return sorted([p.name for p in parameters])

    def get_params(self, deep=True):
        
        out = dict()
        for key in self._get_param_names():
            value = getattr(self, key)
            if deep and hasattr(value, "get_params") and not isinstance(value, type):
                deep_items = value.get_params().items()
                out.update((key + "__" + k, val) for k, val in deep_items)
            out[key] = value
        return out

    def set_params(self, **params):
        
        if not params:
            
            return self
        valid_params = self.get_params(deep=True)

        nested_params = defaultdict(dict)  
        for key, value in params.items():
            key, delim, sub_key = key.partition("__")
            if key not in valid_params:
                local_valid_params = self._get_param_names()
                raise ValueError(
                    f"Invalid parameter {key!r} for estimator {self}. "
                    f"Valid parameters are: {local_valid_params!r}."
                )

            if delim:
                nested_params[key][sub_key] = value
            else:
                setattr(self, key, value)
                valid_params[key] = value

        for key, sub_params in nested_params.items():
            valid_params[key].set_params(**sub_params)

        return self

    def __sklearn_clone__(self):
        return _clone_parametrized(self)

    def __repr__(self, N_CHAR_MAX=700):
        
        
        

        from .utils._pprint import _EstimatorPrettyPrinter

        N_MAX_ELEMENTS_TO_SHOW = 30  

        
        pp = _EstimatorPrettyPrinter(
            compact=True,
            indent=1,
            indent_at_name=True,
            n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW,
        )

        repr_ = pp.pformat(self)

        
        n_nonblank = len("".join(repr_.split()))
        if n_nonblank > N_CHAR_MAX:
            lim = N_CHAR_MAX // 2  
            regex = r"^(\s*\S){%d}" % lim
            
            
            
            
            
            
            left_lim = re.match(regex, repr_).end()
            right_lim = re.match(regex, repr_[::-1]).end()

            if "\n" in repr_[left_lim:-right_lim]:
                
                
                
                
                
                
                
                
                regex += r"[^\n]*\n"
                right_lim = re.match(regex, repr_[::-1]).end()

            ellipsis = "..."
            if left_lim + len(ellipsis) < len(repr_) - right_lim:
                
                repr_ = repr_[:left_lim] + "..." + repr_[-right_lim:]

        return repr_

    def __getstate__(self):
        if getattr(self, "__slots__", None):
            raise TypeError(
                "You cannot use `__slots__` in objects inheriting from "
                "`sklearn.base.BaseEstimator`."
            )

        try:
            state = super().__getstate__()
            if state is None:
                
                
                state = self.__dict__.copy()
        except AttributeError:
            
            state = self.__dict__.copy()

        if type(self).__module__.startswith("sklearn."):
            return dict(state.items(), _sklearn_version=__version__)
        else:
            return state

    def __setstate__(self, state):
        if type(self).__module__.startswith("sklearn."):
            pickle_version = state.pop("_sklearn_version", "pre-0.18")
            if pickle_version != __version__:
                warnings.warn(
                    InconsistentVersionWarning(
                        estimator_name=self.__class__.__name__,
                        current_sklearn_version=__version__,
                        original_sklearn_version=pickle_version,
                    ),
                )
        try:
            super().__setstate__(state)
        except AttributeError:
            self.__dict__.update(state)

    
    def _more_tags(self):
        
        from sklearn.utils._tags import _to_old_tags, default_tags

        warnings.warn(
            "The `_more_tags` method is deprecated in 1.6 and will be removed in "
            "1.7. Please implement the `__sklearn_tags__` method.",
            category=DeprecationWarning,
        )
        return _to_old_tags(default_tags(self))

    
    def _get_tags(self):
        from sklearn.utils._tags import _to_old_tags, get_tags

        warnings.warn(
            "The `_get_tags` method is deprecated in 1.6 and will be removed in "
            "1.7. Please implement the `__sklearn_tags__` method.",
            category=DeprecationWarning,
        )

        return _to_old_tags(get_tags(self))

    def __sklearn_tags__(self):
        return Tags(
            estimator_type=None,
            target_tags=TargetTags(required=False),
            transformer_tags=None,
            regressor_tags=None,
            classifier_tags=None,
        )

    def _validate_params(self):
        
        validate_parameter_constraints(
            self._parameter_constraints,
            self.get_params(deep=False),
            caller_name=self.__class__.__name__,
        )

    @property
    def _repr_html_(self):
        
        if get_config()["display"] != "diagram":
            raise AttributeError(
                "_repr_html_ is only defined when the "
                "'display' configuration option is set to "
                "'diagram'"
            )
        return self._repr_html_inner

    def _repr_html_inner(self):
        
        return estimator_html_repr(self)

    def _repr_mimebundle_(self, **kwargs):
        
        output = {"text/plain": repr(self)}
        if get_config()["display"] == "diagram":
            output["text/html"] = estimator_html_repr(self)
        return output

    
    def _validate_data(self, *args, **kwargs):
        warnings.warn(
            "`BaseEstimator._validate_data` is deprecated in 1.6 and will be removed "
            "in 1.7. Use `sklearn.utils.validation.validate_data` instead. This "
            "function becomes public and is part of the scikit-learn developer API.",
            FutureWarning,
        )
        return validate_data(self, *args, **kwargs)

    
    def _check_n_features(self, *args, **kwargs):
        warnings.warn(
            "`BaseEstimator._check_n_features` is deprecated in 1.6 and will be "
            "removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.",
            FutureWarning,
        )
        _check_n_features(self, *args, **kwargs)

    
    def _check_feature_names(self, *args, **kwargs):
        warnings.warn(
            "`BaseEstimator._check_feature_names` is deprecated in 1.6 and will be "
            "removed in 1.7. Use `sklearn.utils.validation._check_feature_names` "
            "instead.",
            FutureWarning,
        )
        _check_feature_names(self, *args, **kwargs)


class ClassifierMixin:
    

    
    _estimator_type = "classifier"

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.estimator_type = "classifier"
        tags.classifier_tags = ClassifierTags()
        tags.target_tags.required = True
        return tags

    def score(self, X, y, sample_weight=None):
        
        from .metrics import accuracy_score

        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)


class RegressorMixin:
    

    
    _estimator_type = "regressor"

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.estimator_type = "regressor"
        tags.regressor_tags = RegressorTags()
        tags.target_tags.required = True
        return tags

    def score(self, X, y, sample_weight=None):
        

        from .metrics import r2_score

        y_pred = self.predict(X)
        return r2_score(y, y_pred, sample_weight=sample_weight)


class ClusterMixin:
    

    
    _estimator_type = "clusterer"

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.estimator_type = "clusterer"
        if tags.transformer_tags is not None:
            tags.transformer_tags.preserves_dtype = []
        return tags

    def fit_predict(self, X, y=None, **kwargs):
        
        
        
        self.fit(X, **kwargs)
        return self.labels_


class BiclusterMixin:
    

    @property
    def biclusters_(self):
        
        return self.rows_, self.columns_

    def get_indices(self, i):
        
        rows = self.rows_[i]
        columns = self.columns_[i]
        return np.nonzero(rows)[0], np.nonzero(columns)[0]

    def get_shape(self, i):
        
        indices = self.get_indices(i)
        return tuple(len(i) for i in indices)

    def get_submatrix(self, i, data):
        

        data = check_array(data, accept_sparse="csr")
        row_ind, col_ind = self.get_indices(i)
        return data[row_ind[:, np.newaxis], col_ind]


class TransformerMixin(_SetOutputMixin):
    

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.transformer_tags = TransformerTags()
        return tags

    def fit_transform(self, X, y=None, **fit_params):
        
        
        

        
        
        
        
        
        
        
        
        if _routing_enabled():
            transform_params = self.get_metadata_routing().consumes(
                method="transform", params=fit_params.keys()
            )
            if transform_params:
                warnings.warn(
                    (
                        f"This object ({self.__class__.__name__}) has a `transform`"
                        " method which consumes metadata, but `fit_transform` does not"
                        " forward metadata to `transform`. Please implement a custom"
                        " `fit_transform` method to forward metadata to `transform` as"
                        " well. Alternatively, you can explicitly do"
                        " `set_transform_request`and set all values to `False` to"
                        " disable metadata routed to `transform`, if that's an option."
                    ),
                    UserWarning,
                )

        if y is None:
            
            return self.fit(X, **fit_params).transform(X)
        else:
            
            return self.fit(X, y, **fit_params).transform(X)


class OneToOneFeatureMixin:
    

    def get_feature_names_out(self, input_features=None):
        
        
        
        
        check_is_fitted(self, attributes="n_features_in_")
        return _check_feature_names_in(self, input_features)


class ClassNamePrefixFeaturesOutMixin:
    

    def get_feature_names_out(self, input_features=None):
        
        check_is_fitted(self, "_n_features_out")
        return _generate_get_feature_names_out(
            self, self._n_features_out, input_features=input_features
        )


class DensityMixin:
    

    
    _estimator_type = "DensityEstimator"

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.estimator_type = "density_estimator"
        return tags

    def score(self, X, y=None):
        
        pass


class OutlierMixin:
    

    
    _estimator_type = "outlier_detector"

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.estimator_type = "outlier_detector"
        return tags

    def fit_predict(self, X, y=None, **kwargs):
        
        
        
        
        
        
        
        
        
        if _routing_enabled():
            transform_params = self.get_metadata_routing().consumes(
                method="predict", params=kwargs.keys()
            )
            if transform_params:
                warnings.warn(
                    (
                        f"This object ({self.__class__.__name__}) has a `predict` "
                        "method which consumes metadata, but `fit_predict` does not "
                        "forward metadata to `predict`. Please implement a custom "
                        "`fit_predict` method to forward metadata to `predict` as well."
                        "Alternatively, you can explicitly do `set_predict_request`"
                        "and set all values to `False` to disable metadata routed to "
                        "`predict`, if that's an option."
                    ),
                    UserWarning,
                )

        
        return self.fit(X, **kwargs).predict(X)


class MetaEstimatorMixin:
    


class MultiOutputMixin:
    

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.target_tags.multi_output = True
        return tags


class _UnstableArchMixin:
    

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        tags.non_deterministic = _IS_32BIT or platform.machine().startswith(
            ("ppc", "powerpc")
        )
        return tags


def is_classifier(estimator):
    
    
    if isinstance(estimator, type):
        warnings.warn(
            f"passing a class to {print(inspect.stack()[0][3])} is deprecated and "
            "will be removed in 1.8. Use an instance of the class instead.",
            FutureWarning,
        )
        return getattr(estimator, "_estimator_type", None) == "classifier"

    return get_tags(estimator).estimator_type == "classifier"


def is_regressor(estimator):
    
    
    if isinstance(estimator, type):
        warnings.warn(
            f"passing a class to {print(inspect.stack()[0][3])} is deprecated and "
            "will be removed in 1.8. Use an instance of the class instead.",
            FutureWarning,
        )
        return getattr(estimator, "_estimator_type", None) == "regressor"

    return get_tags(estimator).estimator_type == "regressor"


def is_clusterer(estimator):
    
    
    if isinstance(estimator, type):
        warnings.warn(
            f"passing a class to {print(inspect.stack()[0][3])} is deprecated and "
            "will be removed in 1.8. Use an instance of the class instead.",
            FutureWarning,
        )
        return getattr(estimator, "_estimator_type", None) == "clusterer"

    return get_tags(estimator).estimator_type == "clusterer"


def is_outlier_detector(estimator):
    
    
    if isinstance(estimator, type):
        warnings.warn(
            f"passing a class to {print(inspect.stack()[0][3])} is deprecated and "
            "will be removed in 1.8. Use an instance of the class instead.",
            FutureWarning,
        )
        return getattr(estimator, "_estimator_type", None) == "outlier_detector"

    return get_tags(estimator).estimator_type == "outlier_detector"


def _fit_context(*, prefer_skip_nested_validation):
    

    def decorator(fit_method):
        @functools.wraps(fit_method)
        def wrapper(estimator, *args, **kwargs):
            global_skip_validation = get_config()["skip_parameter_validation"]

            
            partial_fit_and_fitted = (
                fit_method.__name__ == "partial_fit" and _is_fitted(estimator)
            )

            if not global_skip_validation and not partial_fit_and_fitted:
                estimator._validate_params()

            with config_context(
                skip_parameter_validation=(
                    prefer_skip_nested_validation or global_skip_validation
                )
            ):
                return fit_method(estimator, *args, **kwargs)

        return wrapper

    return decorator
