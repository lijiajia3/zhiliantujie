




import warnings
from collections import Counter, UserList
from functools import partial
from itertools import chain
from numbers import Integral, Real

import numpy as np
from scipy import sparse

from ..base import TransformerMixin, _fit_context, clone
from ..pipeline import _fit_transform_one, _name_estimators, _transform_one
from ..preprocessing import FunctionTransformer
from ..utils import Bunch
from ..utils._estimator_html_repr import _VisualBlock
from ..utils._indexing import _determine_key_type, _get_column_indices, _safe_indexing
from ..utils._metadata_requests import METHODS
from ..utils._param_validation import HasMethods, Hidden, Interval, StrOptions
from ..utils._set_output import (
    _get_container_adapter,
    _get_output_config,
    _safe_set_output,
)
from ..utils._tags import get_tags
from ..utils.metadata_routing import (
    MetadataRouter,
    MethodMapping,
    _raise_for_params,
    _routing_enabled,
    process_routing,
)
from ..utils.metaestimators import _BaseComposition
from ..utils.parallel import Parallel, delayed
from ..utils.validation import (
    _check_feature_names,
    _check_feature_names_in,
    _check_n_features,
    _get_feature_names,
    _is_pandas_df,
    _num_samples,
    check_array,
    check_is_fitted,
)

__all__ = ["ColumnTransformer", "make_column_transformer", "make_column_selector"]


_ERR_MSG_1DCOLUMN = (
    "1D data passed to a transformer that expects 2D data. "
    "Try to specify the column selection as a list of one "
    "item instead of a scalar."
)


class ColumnTransformer(TransformerMixin, _BaseComposition):
    

    _parameter_constraints: dict = {
        "transformers": [list, Hidden(tuple)],
        "remainder": [
            StrOptions({"drop", "passthrough"}),
            HasMethods(["fit", "transform"]),
            HasMethods(["fit_transform", "transform"]),
        ],
        "sparse_threshold": [Interval(Real, 0, 1, closed="both")],
        "n_jobs": [Integral, None],
        "transformer_weights": [dict, None],
        "verbose": ["verbose"],
        "verbose_feature_names_out": ["boolean", str, callable],
        "force_int_remainder_cols": ["boolean"],
    }

    def __init__(
        self,
        transformers,
        *,
        remainder="drop",
        sparse_threshold=0.3,
        n_jobs=None,
        transformer_weights=None,
        verbose=False,
        verbose_feature_names_out=True,
        force_int_remainder_cols=True,
    ):
        self.transformers = transformers
        self.remainder = remainder
        self.sparse_threshold = sparse_threshold
        self.n_jobs = n_jobs
        self.transformer_weights = transformer_weights
        self.verbose = verbose
        self.verbose_feature_names_out = verbose_feature_names_out
        self.force_int_remainder_cols = force_int_remainder_cols

    @property
    def _transformers(self):
        
        try:
            return [(name, trans) for name, trans, _ in self.transformers]
        except (TypeError, ValueError):
            return self.transformers

    @_transformers.setter
    def _transformers(self, value):
        
        try:
            self.transformers = [
                (name, trans, col)
                for ((name, trans), (_, _, col)) in zip(value, self.transformers)
            ]
        except (TypeError, ValueError):
            self.transformers = value

    def set_output(self, *, transform=None):
        
        super().set_output(transform=transform)

        transformers = (
            trans
            for _, trans, _ in chain(
                self.transformers, getattr(self, "transformers_", [])
            )
            if trans not in {"passthrough", "drop"}
        )
        for trans in transformers:
            _safe_set_output(trans, transform=transform)

        if self.remainder not in {"passthrough", "drop"}:
            _safe_set_output(self.remainder, transform=transform)

        return self

    def get_params(self, deep=True):
        
        return self._get_params("_transformers", deep=deep)

    def set_params(self, **kwargs):
        
        self._set_params("_transformers", **kwargs)
        return self

    def _iter(self, fitted, column_as_labels, skip_drop, skip_empty_columns):
        
        if fitted:
            transformers = self.transformers_
        else:
            
            transformers = [
                (name, trans, column)
                for (name, trans, _), column in zip(self.transformers, self._columns)
            ]
            
            if self._remainder[2]:
                transformers = chain(transformers, [self._remainder])

        
        
        
        
        
        transformers = _with_dtype_warning_enabled_set_to(False, transformers)

        get_weight = (self.transformer_weights or {}).get

        for name, trans, columns in transformers:
            if skip_drop and trans == "drop":
                continue
            if skip_empty_columns and _is_empty_column_selection(columns):
                continue

            if column_as_labels:
                
                columns_is_scalar = np.isscalar(columns)

                indices = self._transformer_to_input_indices[name]
                columns = self.feature_names_in_[indices]

                if columns_is_scalar:
                    
                    columns = columns[0]

            yield (name, trans, columns, get_weight(name))

    def _validate_transformers(self):
        
        if not self.transformers:
            return

        names, transformers, _ = zip(*self.transformers)

        
        self._validate_names(names)

        
        for t in transformers:
            if t in ("drop", "passthrough"):
                continue
            if not (hasattr(t, "fit") or hasattr(t, "fit_transform")) or not hasattr(
                t, "transform"
            ):
                
                raise TypeError(
                    "All estimators should implement fit and "
                    "transform, or can be 'drop' or 'passthrough' "
                    "specifiers. '%s' (type %s) doesn't." % (t, type(t))
                )

    def _validate_column_callables(self, X):
        
        all_columns = []
        transformer_to_input_indices = {}
        for name, _, columns in self.transformers:
            if callable(columns):
                columns = columns(X)
            all_columns.append(columns)
            transformer_to_input_indices[name] = _get_column_indices(X, columns)

        self._columns = all_columns
        self._transformer_to_input_indices = transformer_to_input_indices

    def _validate_remainder(self, X):
        
        cols = set(chain(*self._transformer_to_input_indices.values()))
        remaining = sorted(set(range(self.n_features_in_)) - cols)
        self._transformer_to_input_indices["remainder"] = remaining
        remainder_cols = self._get_remainder_cols(remaining)
        self._remainder = ("remainder", self.remainder, remainder_cols)

    def _get_remainder_cols_dtype(self):
        try:
            all_dtypes = {_determine_key_type(c) for (*_, c) in self.transformers}
            if len(all_dtypes) == 1:
                return next(iter(all_dtypes))
        except ValueError:
            
            
            return "int"
        return "int"

    def _get_remainder_cols(self, indices):
        dtype = self._get_remainder_cols_dtype()
        if self.force_int_remainder_cols and dtype != "int":
            return _RemainderColsList(indices, future_dtype=dtype)
        if dtype == "str":
            return list(self.feature_names_in_[indices])
        if dtype == "bool":
            return [i in indices for i in range(self.n_features_in_)]
        return indices

    @property
    def named_transformers_(self):
        
        
        return Bunch(**{name: trans for name, trans, _ in self.transformers_})

    def _get_feature_name_out_for_transformer(self, name, trans, feature_names_in):
        
        column_indices = self._transformer_to_input_indices[name]
        names = feature_names_in[column_indices]
        
        if not hasattr(trans, "get_feature_names_out"):
            raise AttributeError(
                f"Transformer {name} (type {type(trans).__name__}) does "
                "not provide get_feature_names_out."
            )
        return trans.get_feature_names_out(names)

    def get_feature_names_out(self, input_features=None):
        
        check_is_fitted(self)
        input_features = _check_feature_names_in(self, input_features)

        
        transformer_with_feature_names_out = []
        for name, trans, *_ in self._iter(
            fitted=True,
            column_as_labels=False,
            skip_empty_columns=True,
            skip_drop=True,
        ):
            feature_names_out = self._get_feature_name_out_for_transformer(
                name, trans, input_features
            )
            if feature_names_out is None:
                continue
            transformer_with_feature_names_out.append((name, feature_names_out))

        if not transformer_with_feature_names_out:
            
            return np.array([], dtype=object)

        return self._add_prefix_for_feature_names_out(
            transformer_with_feature_names_out
        )

    def _add_prefix_for_feature_names_out(self, transformer_with_feature_names_out):
        
        feature_names_out_callable = None
        if callable(self.verbose_feature_names_out):
            feature_names_out_callable = self.verbose_feature_names_out
        elif isinstance(self.verbose_feature_names_out, str):
            feature_names_out_callable = partial(
                _feature_names_out_with_str_format,
                str_format=self.verbose_feature_names_out,
            )
        elif self.verbose_feature_names_out is True:
            feature_names_out_callable = partial(
                _feature_names_out_with_str_format,
                str_format="{transformer_name}__{feature_name}",
            )

        if feature_names_out_callable is not None:
            
            names = list(
                chain.from_iterable(
                    (feature_names_out_callable(name, i) for i in feature_names_out)
                    for name, feature_names_out in transformer_with_feature_names_out
                )
            )
            return np.asarray(names, dtype=object)

        
        
        feature_names_count = Counter(
            chain.from_iterable(s for _, s in transformer_with_feature_names_out)
        )
        top_6_overlap = [
            name for name, count in feature_names_count.most_common(6) if count > 1
        ]
        top_6_overlap.sort()
        if top_6_overlap:
            if len(top_6_overlap) == 6:
                
                
                names_repr = str(top_6_overlap[:5])[:-1] + ", ...]"
            else:
                names_repr = str(top_6_overlap)
            raise ValueError(
                f"Output feature names: {names_repr} are not unique. Please set "
                "verbose_feature_names_out=True to add prefixes to feature names"
            )

        return np.concatenate(
            [name for _, name in transformer_with_feature_names_out],
        )

    def _update_fitted_transformers(self, transformers):
        
        
        fitted_transformers = iter(transformers)
        transformers_ = []

        for name, old, column, _ in self._iter(
            fitted=False,
            column_as_labels=False,
            skip_drop=False,
            skip_empty_columns=False,
        ):
            if old == "drop":
                trans = "drop"
            elif _is_empty_column_selection(column):
                trans = old
            else:
                trans = next(fitted_transformers)
            transformers_.append((name, trans, column))

        
        assert not list(fitted_transformers)
        self.transformers_ = _with_dtype_warning_enabled_set_to(True, transformers_)

    def _validate_output(self, result):
        
        names = [
            name
            for name, _, _, _ in self._iter(
                fitted=True,
                column_as_labels=False,
                skip_drop=True,
                skip_empty_columns=True,
            )
        ]
        for Xs, name in zip(result, names):
            if not getattr(Xs, "ndim", 0) == 2 and not hasattr(Xs, "__dataframe__"):
                raise ValueError(
                    "The output of the '{0}' transformer should be 2D (numpy array, "
                    "scipy sparse array, dataframe).".format(name)
                )
        if _get_output_config("transform", self)["dense"] == "pandas":
            return
        try:
            import pandas as pd
        except ImportError:
            return
        for Xs, name in zip(result, names):
            if not _is_pandas_df(Xs):
                continue
            for col_name, dtype in Xs.dtypes.to_dict().items():
                if getattr(dtype, "na_value", None) is not pd.NA:
                    continue
                if pd.NA not in Xs[col_name].values:
                    continue
                class_name = self.__class__.__name__
                raise ValueError(
                    f"The output of the '{name}' transformer for column"
                    f" '{col_name}' has dtype {dtype} and uses pandas.NA to"
                    " represent null values. Storing this output in a numpy array"
                    " can cause errors in downstream scikit-learn estimators, and"
                    " inefficiencies. To avoid this problem you can (i)"
                    " store the output in a pandas DataFrame by using"
                    f" {class_name}.set_output(transform='pandas') or (ii) modify"
                    f" the input data or the '{name}' transformer to avoid the"
                    " presence of pandas.NA (for example by using"
                    " pandas.DataFrame.astype)."
                )

    def _record_output_indices(self, Xs):
        
        idx = 0
        self.output_indices_ = {}

        for transformer_idx, (name, _, _, _) in enumerate(
            self._iter(
                fitted=True,
                column_as_labels=False,
                skip_drop=True,
                skip_empty_columns=True,
            )
        ):
            n_columns = Xs[transformer_idx].shape[1]
            self.output_indices_[name] = slice(idx, idx + n_columns)
            idx += n_columns

        
        
        
        all_names = [t[0] for t in self.transformers] + ["remainder"]
        for name in all_names:
            if name not in self.output_indices_:
                self.output_indices_[name] = slice(0, 0)

    def _log_message(self, name, idx, total):
        if not self.verbose:
            return None
        return "(%d of %d) Processing %s" % (idx, total, name)

    def _call_func_on_transformers(self, X, y, func, column_as_labels, routed_params):
        
        if func is _fit_transform_one:
            fitted = False
        else:  
            fitted = True

        transformers = list(
            self._iter(
                fitted=fitted,
                column_as_labels=column_as_labels,
                skip_drop=True,
                skip_empty_columns=True,
            )
        )
        try:
            jobs = []
            for idx, (name, trans, columns, weight) in enumerate(transformers, start=1):
                if func is _fit_transform_one:
                    if trans == "passthrough":
                        output_config = _get_output_config("transform", self)
                        trans = FunctionTransformer(
                            accept_sparse=True,
                            check_inverse=False,
                            feature_names_out="one-to-one",
                        ).set_output(transform=output_config["dense"])

                    extra_args = dict(
                        message_clsname="ColumnTransformer",
                        message=self._log_message(name, idx, len(transformers)),
                    )
                else:  
                    extra_args = {}
                jobs.append(
                    delayed(func)(
                        transformer=clone(trans) if not fitted else trans,
                        X=_safe_indexing(X, columns, axis=1),
                        y=y,
                        weight=weight,
                        **extra_args,
                        params=routed_params[name],
                    )
                )

            return Parallel(n_jobs=self.n_jobs)(jobs)

        except ValueError as e:
            if "Expected 2D array, got 1D array instead" in str(e):
                raise ValueError(_ERR_MSG_1DCOLUMN) from e
            else:
                raise

    def fit(self, X, y=None, **params):
        
        _raise_for_params(params, self, "fit")
        
        
        self.fit_transform(X, y=y, **params)
        return self

    @_fit_context(
        
        prefer_skip_nested_validation=False
    )
    def fit_transform(self, X, y=None, **params):
        
        _raise_for_params(params, self, "fit_transform")
        _check_feature_names(self, X, reset=True)

        X = _check_X(X)
        
        _check_n_features(self, X, reset=True)
        self._validate_transformers()
        n_samples = _num_samples(X)

        self._validate_column_callables(X)
        self._validate_remainder(X)

        if _routing_enabled():
            routed_params = process_routing(self, "fit_transform", **params)
        else:
            routed_params = self._get_empty_routing()

        result = self._call_func_on_transformers(
            X,
            y,
            _fit_transform_one,
            column_as_labels=False,
            routed_params=routed_params,
        )

        if not result:
            self._update_fitted_transformers([])
            
            return np.zeros((n_samples, 0))

        Xs, transformers = zip(*result)

        
        if any(sparse.issparse(X) for X in Xs):
            nnz = sum(X.nnz if sparse.issparse(X) else X.size for X in Xs)
            total = sum(
                X.shape[0] * X.shape[1] if sparse.issparse(X) else X.size for X in Xs
            )
            density = nnz / total
            self.sparse_output_ = density < self.sparse_threshold
        else:
            self.sparse_output_ = False

        self._update_fitted_transformers(transformers)
        self._validate_output(Xs)
        self._record_output_indices(Xs)

        return self._hstack(list(Xs), n_samples=n_samples)

    def transform(self, X, **params):
        
        _raise_for_params(params, self, "transform")
        check_is_fitted(self)
        X = _check_X(X)

        
        
        
        
        
        fit_dataframe_and_transform_dataframe = hasattr(self, "feature_names_in_") and (
            _is_pandas_df(X) or hasattr(X, "__dataframe__")
        )

        n_samples = _num_samples(X)
        column_names = _get_feature_names(X)

        if fit_dataframe_and_transform_dataframe:
            named_transformers = self.named_transformers_
            
            
            non_dropped_indices = [
                ind
                for name, ind in self._transformer_to_input_indices.items()
                if name in named_transformers and named_transformers[name] != "drop"
            ]

            all_indices = set(chain(*non_dropped_indices))
            all_names = set(self.feature_names_in_[ind] for ind in all_indices)

            diff = all_names - set(column_names)
            if diff:
                raise ValueError(f"columns are missing: {diff}")
        else:
            
            
            _check_n_features(self, X, reset=False)

        if _routing_enabled():
            routed_params = process_routing(self, "transform", **params)
        else:
            routed_params = self._get_empty_routing()

        Xs = self._call_func_on_transformers(
            X,
            None,
            _transform_one,
            column_as_labels=fit_dataframe_and_transform_dataframe,
            routed_params=routed_params,
        )
        self._validate_output(Xs)

        if not Xs:
            
            return np.zeros((n_samples, 0))

        return self._hstack(list(Xs), n_samples=n_samples)

    def _hstack(self, Xs, *, n_samples):
        
        if self.sparse_output_:
            try:
                
                
                
                converted_Xs = [
                    check_array(X, accept_sparse=True, ensure_all_finite=False)
                    for X in Xs
                ]
            except ValueError as e:
                raise ValueError(
                    "For a sparse output, all columns should "
                    "be a numeric or convertible to a numeric."
                ) from e

            return sparse.hstack(converted_Xs).tocsr()
        else:
            Xs = [f.toarray() if sparse.issparse(f) else f for f in Xs]
            adapter = _get_container_adapter("transform", self)
            if adapter and all(adapter.is_supported_container(X) for X in Xs):
                
                
                transformer_names = [
                    t[0]
                    for t in self._iter(
                        fitted=True,
                        column_as_labels=False,
                        skip_drop=True,
                        skip_empty_columns=True,
                    )
                ]
                feature_names_outs = [X.columns for X in Xs if X.shape[1] != 0]
                if self.verbose_feature_names_out:
                    
                    
                    feature_names_outs = self._add_prefix_for_feature_names_out(
                        list(zip(transformer_names, feature_names_outs))
                    )
                else:
                    
                    feature_names_outs = list(chain.from_iterable(feature_names_outs))
                    feature_names_count = Counter(feature_names_outs)
                    if any(count > 1 for count in feature_names_count.values()):
                        duplicated_feature_names = sorted(
                            name
                            for name, count in feature_names_count.items()
                            if count > 1
                        )
                        err_msg = (
                            "Duplicated feature names found before concatenating the"
                            " outputs of the transformers:"
                            f" {duplicated_feature_names}.\n"
                        )
                        for transformer_name, X in zip(transformer_names, Xs):
                            if X.shape[1] == 0:
                                continue
                            dup_cols_in_transformer = sorted(
                                set(X.columns).intersection(duplicated_feature_names)
                            )
                            if len(dup_cols_in_transformer):
                                err_msg += (
                                    f"Transformer {transformer_name} has conflicting "
                                    f"columns names: {dup_cols_in_transformer}.\n"
                                )
                        raise ValueError(
                            err_msg
                            + "Either make sure that the transformers named above "
                            "do not generate columns with conflicting names or set "
                            "verbose_feature_names_out=True to automatically "
                            "prefix to the output feature names with the name "
                            "of the transformer to prevent any conflicting "
                            "names."
                        )

                names_idx = 0
                for X in Xs:
                    if X.shape[1] == 0:
                        continue
                    names_out = feature_names_outs[names_idx : names_idx + X.shape[1]]
                    adapter.rename_columns(X, names_out)
                    names_idx += X.shape[1]

                output = adapter.hstack(Xs)
                output_samples = output.shape[0]
                if output_samples != n_samples:
                    raise ValueError(
                        "Concatenating DataFrames from the transformer's output lead to"
                        " an inconsistent number of samples. The output may have Pandas"
                        " Indexes that do not match, or that transformers are returning"
                        " number of samples which are not the same as the number input"
                        " samples."
                    )

                return output

            return np.hstack(Xs)

    def _sk_visual_block_(self):
        if isinstance(self.remainder, str) and self.remainder == "drop":
            transformers = self.transformers
        elif hasattr(self, "_remainder"):
            remainder_columns = self._remainder[2]
            if (
                hasattr(self, "feature_names_in_")
                and remainder_columns
                and not all(isinstance(col, str) for col in remainder_columns)
            ):
                remainder_columns = self.feature_names_in_[remainder_columns].tolist()
            transformers = chain(
                self.transformers, [("remainder", self.remainder, remainder_columns)]
            )
        else:
            transformers = chain(self.transformers, [("remainder", self.remainder, "")])

        names, transformers, name_details = zip(*transformers)
        return _VisualBlock(
            "parallel", transformers, names=names, name_details=name_details
        )

    def __getitem__(self, key):
        try:
            return self.named_transformers_[key]
        except AttributeError as e:
            raise TypeError(
                "ColumnTransformer is subscriptable after it is fitted"
            ) from e
        except KeyError as e:
            raise KeyError(f"'{key}' is not a valid transformer name") from e

    def _get_empty_routing(self):
        
        return Bunch(
            **{
                name: Bunch(**{method: {} for method in METHODS})
                for name, step, _, _ in self._iter(
                    fitted=False,
                    column_as_labels=False,
                    skip_drop=True,
                    skip_empty_columns=True,
                )
            }
        )

    def get_metadata_routing(self):
        
        router = MetadataRouter(owner=self.__class__.__name__)
        
        
        
        
        transformers = chain(self.transformers, [("remainder", self.remainder, None)])
        for name, step, _ in transformers:
            method_mapping = MethodMapping()
            if hasattr(step, "fit_transform"):
                (
                    method_mapping.add(caller="fit", callee="fit_transform").add(
                        caller="fit_transform", callee="fit_transform"
                    )
                )
            else:
                (
                    method_mapping.add(caller="fit", callee="fit")
                    .add(caller="fit", callee="transform")
                    .add(caller="fit_transform", callee="fit")
                    .add(caller="fit_transform", callee="transform")
                )
            method_mapping.add(caller="transform", callee="transform")
            router.add(method_mapping=method_mapping, **{name: step})

        return router

    def __sklearn_tags__(self):
        tags = super().__sklearn_tags__()
        try:
            tags.input_tags.sparse = all(
                get_tags(trans).input_tags.sparse
                for name, trans, _ in self.transformers
                if trans not in {"passthrough", "drop"}
            )
        except Exception:
            
            
            
            pass  
        return tags


def _check_X(X):
    
    if (
        (hasattr(X, "__array__") and hasattr(X, "shape"))
        or hasattr(X, "__dataframe__")
        or sparse.issparse(X)
    ):
        return X
    return check_array(X, ensure_all_finite="allow-nan", dtype=object)


def _is_empty_column_selection(column):
    
    if hasattr(column, "dtype") and np.issubdtype(column.dtype, np.bool_):
        return not column.any()
    elif hasattr(column, "__len__"):
        return (
            len(column) == 0
            or all(isinstance(col, bool) for col in column)
            and not any(column)
        )
    else:
        return False


def _get_transformer_list(estimators):
    
    transformers, columns = zip(*estimators)
    names, _ = zip(*_name_estimators(transformers))

    transformer_list = list(zip(names, transformers, columns))
    return transformer_list




def make_column_transformer(
    *transformers,
    remainder="drop",
    sparse_threshold=0.3,
    n_jobs=None,
    verbose=False,
    verbose_feature_names_out=True,
    force_int_remainder_cols=True,
):
    
    
    
    transformer_list = _get_transformer_list(transformers)
    return ColumnTransformer(
        transformer_list,
        n_jobs=n_jobs,
        remainder=remainder,
        sparse_threshold=sparse_threshold,
        verbose=verbose,
        verbose_feature_names_out=verbose_feature_names_out,
        force_int_remainder_cols=force_int_remainder_cols,
    )


class make_column_selector:
    

    def __init__(self, pattern=None, *, dtype_include=None, dtype_exclude=None):
        self.pattern = pattern
        self.dtype_include = dtype_include
        self.dtype_exclude = dtype_exclude

    def __call__(self, df):
        
        if not hasattr(df, "iloc"):
            raise ValueError(
                "make_column_selector can only be applied to pandas dataframes"
            )
        df_row = df.iloc[:1]
        if self.dtype_include is not None or self.dtype_exclude is not None:
            df_row = df_row.select_dtypes(
                include=self.dtype_include, exclude=self.dtype_exclude
            )
        cols = df_row.columns
        if self.pattern is not None:
            cols = cols[cols.str.contains(self.pattern, regex=True)]
        return cols.tolist()


class _RemainderColsList(UserList):
    

    def __init__(
        self,
        columns,
        *,
        future_dtype=None,
        warning_was_emitted=False,
        warning_enabled=True,
    ):
        super().__init__(columns)
        self.future_dtype = future_dtype
        self.warning_was_emitted = warning_was_emitted
        self.warning_enabled = warning_enabled

    def __getitem__(self, index):
        self._show_remainder_cols_warning()
        return super().__getitem__(index)

    def _show_remainder_cols_warning(self):
        if self.warning_was_emitted or not self.warning_enabled:
            return
        self.warning_was_emitted = True
        future_dtype_description = {
            "str": "column names (of type str)",
            "bool": "a mask array (of type bool)",
            
            
            None: "a different type depending on the ColumnTransformer inputs",
        }.get(self.future_dtype, self.future_dtype)

        
        
        warnings.warn(
            (
                "\nThe format of the columns of the 'remainder' transformer in"
                " ColumnTransformer.transformers_ will change in version 1.7 to"
                " match the format of the other transformers.\nAt the moment the"
                " remainder columns are stored as indices (of type int). With the same"
                " ColumnTransformer configuration, in the future they will be stored"
                f" as {future_dtype_description}.\nTo use the new behavior now and"
                " suppress this warning, use"
                " ColumnTransformer(force_int_remainder_cols=False).\n"
            ),
            category=FutureWarning,
        )

    def _repr_pretty_(self, printer, *_):
        
        printer.text(repr(self.data))


def _with_dtype_warning_enabled_set_to(warning_enabled, transformers):
    result = []
    for name, trans, columns in transformers:
        if isinstance(columns, _RemainderColsList):
            columns = _RemainderColsList(
                columns.data,
                future_dtype=columns.future_dtype,
                warning_was_emitted=columns.warning_was_emitted,
                warning_enabled=warning_enabled,
            )
        result.append((name, trans, columns))
    return result


def _feature_names_out_with_str_format(
    transformer_name: str, feature_name: str, str_format: str
) -> str:
    return str_format.format(
        transformer_name=transformer_name, feature_name=feature_name
    )
